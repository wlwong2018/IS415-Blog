---
title: "Hands-on Exercise 7"
description: |
  In Hands-on Exercise 7, I have learnt how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package.
author:
  - name: Wong Wei Ling
    url: www.google.com
date: 09-26-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# 1 Objectives

In spatial policy, one of the main development objective of the local govenment and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”

In this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.(https://en.wikipedia.org/wiki/Hunan)

# 2 Data

- Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.
- Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.

# 3 Packages Used

- sf is use for importing and handling geospatial data in R,
- tidyverse is mainly use for wrangling attribute data in R,
- spdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and
- tmap will be used to prepare cartographic quality chropleth map.

```{r eval=TRUE, echo = TRUE}
packages = c('sf', 'spdep', 'tmap', 'tidyverse', 'ggplot2')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
```

# 4 Getting the Data Into R Environment

Bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv format.

# 4.1 Import shapefile into r environment

- Uses *st_read()* of **sf** package to import Hunan shapefile into R.
- The imported shapefile will be simple features Object of sf.

```{r eval=TRUE, echo = TRUE}
hunan <- st_read(dsn = "data/shapefile", 
                 layer = "Hunan")
```

# 4.2 Import csv file into r environment

- Import Hunan_2012.csv into R by using read_csv() of readr package.
- The output is R data frame class.

```{r eval=TRUE, echo = TRUE}
hunan2012 <- read_csv("data/attribute/Hunan_2012.csv")
```

# 4.3 Performing relational join

- To update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe.
- This is performed by using left_join() of dplyr package.

```{r eval=TRUE, echo = TRUE}
hunan <- left_join(hunan,hunan2012)
```

# 4.4 Visualising Regional Development Indicator

- Prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.

```{r eval=TRUE, echo = TRUE, fig.width=12, fig.height=8}
basemap <- tm_shape(hunan) +
  tm_polygons() +
  tm_text("NAME_3", size=0.5)

gdppc <- qtm(hunan, "GDPPC")
tmap_arrange(basemap, gdppc, asp=1, ncol=2)
```

# 5 Global Spatial Autocorrelation

Compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.

## 5.1 Computing Contiguity Spatial Weights

Before we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.

- In the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area.
- This function builds a neighbours list based on regions with contiguous boundaries.
- Can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE. If queens = False, we are using rooks method.

Code chunk below is used to compute Queen contiguity weight matrix.

```{r eval=TRUE, echo = TRUE}
wm_q <- poly2nb(hunan, queen=TRUE)
summary(wm_q)
```

Results above show that:

- There are 88 area units in Hunan.
- The most connected area unit has 11 neighbours.
- There are two area units with only one neighbours.

## 5.1.1 Row-standardised weights matrix

- Next, we need to assign weights to each neighboring polygon.
- In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values.
- While this is the most intuitive way to summaries the neighbors’ values it has one **drawback** in that polygons along the edges of the study area will be based on their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.
- For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other **more robust options are available, notably style=“B”**.

<br>

- *nb2listw()* computes weight matrix
- zero.policy=TRUE option allows for lists of non-neighbors.
This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.

```{r eval=TRUE, echo = TRUE}
rswm_q <- nb2listw(wm_q, style="W", zero.policy = TRUE)
rswm_q
```

## 5.2 Global Spatial Autocorrelation: Moran’s I

Perform Moran’s I statistics testing by using moran.test() of spdep.

## 5.2.1 Maron’s I test

- input x must be a numeric vector (**Note:** have to specify both the df and the variable name)
- list is computed using weight matrix
- na.action to handle na values

- Not used in this code chunk: 

    + alternative: to define alternative hypothesis . Default is "greater" (not used in this code chunk)
    + rank: dont have because we usually use continuous data. if Not using continuous data, change to True.

- We are using 99.9% as we are running 1000 simulation, making the alpha value: 0.001

    + 99 % critical value 0.01, 
    + 99.9 critical value is 0.001 , number of simulations: 1000
    + 90% critical value is 0.1, number of simulations: 100
    
- The code chunk below performs Moran’s I statistical testing using moran.test() of spdep.

```{r eval=TRUE, echo = TRUE}
moran.test(hunan$GDPPC, listw=rswm_q, zero.policy = TRUE, na.action=na.omit)

```

Question: What statistical conclusion can you draw from the output above?

Since the p-value is smaller than the alpha value, we have enough statistical hypothesis to reject the null hypothesis at 99.9% confidence interval.

Also, since Moran I is greater than 0, which is approaching 1, this shows a positive autocorrelation. We can then infer that the spatial pattern observed resembles cluster. 

alternative hypothesis: greater (1 tier)

## 5.2.2 Computing Monte Carlo Moran’s I

- The code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep.
- A total of 1000 simulation will be performed.
- *set.seed()* to keep the simulation the same for each run.

```{r eval=TRUE, echo = TRUE}
set.seed(1234)
bperm= moran.mc(hunan$GDPPC, listw=rswm_q, nsim=999, zero.policy = TRUE, na.action=na.omit)
bperm

```

Question: What statistical conclusion can you draw from the output above?

Since the p-value is not smaller than the alpha value, we do have enough statistical hypothesis to reject the null hypothesis at 99.9% confidence interval.

Even though Moran I is greater than 0, which is approaching 1, and shows a positive autocorrelation, we are unable to statistically prove that the spatial pattern observed resembles cluster since the p-value is not smaller than the alpha value.

## 5.2.3 Visualising Monte Carlo Moran’s I

- Good practice to examine the simulated Moran’s I test statistics in greater detail.
- This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.


```{r eval=TRUE, echo = TRUE}
mean(bperm$res[1:999])
var(bperm$res[1:999])
summary(bperm$res[1:999])

```



```{r eval=TRUE, echo = TRUE}
hist(bperm$res, freq=TRUE, breaks=20, xlab="Simulated Moran's I")
abline(v=0, col="red") 
```

Question: What statistical observation can you draw from the output above?

The distribution above is right skewed.

**Challenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package.**

```{r eval=TRUE, echo = TRUE}
hist_df<-as.data.frame(bperm$res)
head(hist_df)
```

```{r eval=TRUE, echo = TRUE}
ggplot(hist_df, 
       aes(x= as.numeric(`bperm$res`)))+
  geom_histogram(bins=20, 
                 color="black",
                 fill="grey") +
  geom_vline(aes(xintercept=0),
             color="blue", size=1) +
  labs(title = "Distribution of Monte Carlo Moran’s I statistics (Using GGPLOT2)",
      x = "Simulated Moran's I",
      y = "Frequency")
```

## 5.3 Global Spatial Autocorrelation: Geary’s

Perform Geary’s c statistics testing by using appropriate functions of spdep package.

## 5.3.1 Geary’s C test

The code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.

```{r eval=TRUE, echo = TRUE}
geary.test(hunan$GDPPC, listw=rswm_q)

```

Question: What statistical conclusion can you draw from the output above? 

Since the p-value is smaller than the alpha value, we have enough statistical hypothesis to reject the null hypothesis at 99.9% confidence interval.

Also, since Geary C is smaller than 1, approaching 0, infer that the spatial pattern observed resembles cluster. 

## 5.3.2 Computing Monte Carlo Geary’s C

The code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.

```{r eval=TRUE, echo = TRUE}
set.seed(1234)
bperm=geary.mc(hunan$GDPPC, listw=rswm_q, nsim=999)
bperm
```

Question: What statistical conclusion can you draw from the output above?

Since the p-value is not smaller than the alpha value, we do have enough statistical hypothesis to reject the null hypothesis at 99.9% confidence interval.

Even though, Geary C is smaller than 1, approaching 0, we do not have enough statistical significance to infer that the spatial pattern observed resembles cluster. 

## 5.3.3 Visualising the Monte Carlo Geary’s C

- Plot a histogram to reveal the distribution of the simulated values by using the code chunk below.

```{r eval=TRUE, echo = TRUE}
mean(bperm$res[1:999])
var(bperm$res[1:999])
summary(bperm$res[1:999])

```

```{r eval=TRUE, echo = TRUE}
hist(bperm$res, freq=TRUE, breaks=20, xlab="Simulated Geary c")
abline(v=1, col="red") 
```

Question: What statistical observation can you draw from the output?

The distribution above is close to normal distribution.


**Note:** With Gearcy C, we are more certain to reject the null hypothesis. 



## 5.4 Spatial Correlogram

- Spatial correlograms are for examining patterns of spatial autocorrelation in the data or model residuals.
- They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.
- Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool.
- For this purpose they actually provide richer information than variograms.

## 5.4.1 Compute Moran’s I correlogram

-  *sp.correlogram()* (can perform either Moran I or Geary C) of **spdep** package is used to compute a 6-lag (using *order* argument) spatial correlogram of GDPPC.
- The global spatial autocorrelation used in Moran’s I.
- The plot() of base Graph is then used to plot the output.

```{r eval=TRUE, echo = TRUE}
MI_corr <- sp.correlogram(wm_q, hunan$GDPPC, order=6, method="I", style="B")
plot(MI_corr)

```
Results above: 

- As the lags increases, it becomes more regular and less cluster. 

```{r eval=TRUE, echo = TRUE}
print(MI_corr)
```

Question: What statistical observation can you draw from the plot above?

- Lag 4 is not statistically significant, 
    
    + When comparing the p-value of lag 4 i.e. 0.226015 to the alpha value, it is greater than any of the commonly used alpha values. 
    + This can also be observed that there are no asterisks behind the p-value, this shows that it is not statiscally signifcant
    
- Hence, we can ony reject the null hypothesis at lag 1, 2 and 5 as all the p-values are smaller than 0.001 which allows to draw conclusions at 99.9% confidence interval.


## 5.4.2 Compute Geary’s C correlogram and plot

- *sp.correlogram()* of **spdep package** is used to compute a 6-lag spatial correlogram of GDPPC.
- The global spatial autocorrelation used in Geary’s C.
- The plot() of base Graph is then used to plot the output.

```{r eval=TRUE, echo = TRUE}
GC_corr <- sp.correlogram(wm_q, hunan$GDPPC, order=6, method="C", style="W")
plot(GC_corr)
```

# 6 Cluster and Outlier Analysis

- Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. 
- For instance if we are studying cancer rates among census tracts in a given city local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.

- In this section, we wil apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.

## 6.1 Computing local Moran’s I

- *localmoran()* function of **spdep** will be used.
- It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.

- The code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.

```{r eval=TRUE, echo = TRUE}
fips <- order(hunan$County)
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

localmoran() function returns a matrix of values whose columns are:

- Ii: the local Moran’s I statistics
- E.Ii: the expectation of local moran statistic under the randomisation hypothesis
- Var.Ii: the variance of local moran statistic under the randomisation hypothesis
- Z.Ii:the standard deviate of local moran statistic
- Pr(): the p-value of local moran statistic

The code chunk below list the content of the local Moran matrix derived by using printCoefmat().

```{r eval=TRUE, echo = TRUE}
printCoefmat(data.frame(localMI[fips,], row.names=hunan$County[fips]), check.names=FALSE)

```

- Local moran I can plot as there are individual values.

## 6.2 Mapping the local Moran’s I

- Before mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame.
- The code chunks below can be used to perform the task. 

```{r eval=TRUE, echo = TRUE}
hunan.localMI <- cbind(hunan,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

### 6.2.1 Mapping local Moran’s I values

- Using choropleth mapping functions of tmap package, we can plot the local Moran’s I values. 

```{r eval=TRUE, echo = TRUE}
tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

### 6.2.2 Mapping local Moran’s I p-values

- The choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.

- The code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.

```{r eval=TRUE, echo = TRUE}
tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

### 6.2.3 Mapping both local Moran’s I values and p-values

- For effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.

```{r eval=TRUE, echo = TRUE}
localMI.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

Results above show that: 

- Only the dark colours are 99.9% confident.
- The areas with dark green and blue are statistically significant that it has positive autocorrelation. 
- We can then decompose this relationship using LISA (section below)

## 6.3 Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.

### 6.3.1 Plotting Moran scatterplot

- The Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.

- The code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.

```{r eval=TRUE, echo = TRUE}
nci <- moran.plot(hunan$GDPPC, rswm_q,
                  labels=as.character(hunan$County), 
                  xlab="GDPPC 2012", 
                  ylab="Spatially Lag GDPPC 2012")
```

Results above show that:

- **Note:** Plot is split in 4 quadrants.
- The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. 


### 6.3.2 Plotting Moran scatterplot with standardised variable

- Use scale() to centers and scales the variable. (to cut off at zero for both axis)
- Here, centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.
- The as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.

```{r eval=TRUE, echo = TRUE}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>% as.vector 

```

- Plot the Moran scatterplot again by using the code chunk below

```{r eval=TRUE, echo = TRUE}
nci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,
                   labels=as.character(hunan$County),
                   xlab="z-GDPPC 2012", 
                   ylab="Spatially Lag z-GDPPC 2012")
```

### 6.3.3 Preparing LISA map classes

- Prepare a LISA cluster map.

```{r eval=TRUE, echo = TRUE}
quadrant <- vector(mode="numeric",length=nrow(localMI))

```

- Center the variable of interest around its mean.

```{r eval=TRUE, echo = TRUE}
DV <- hunan$GDPPC - mean(hunan$GDPPC)     

```

- Center the local Moran’s around the mean.

```{r eval=TRUE, echo = TRUE}
C_mI <- localMI[,1] - mean(localMI[,1])    

```

- Set a statistical significance level for the local Moran.

```{r eval=TRUE, echo = TRUE}
signif <- 0.05
```

- These four command lines define the high-high, low-low, low-high and high-low categories.

```{r eval=TRUE, echo = TRUE}
quadrant[DV >0 & C_mI>0] <- 4      
quadrant[DV <0 & C_mI<0] <- 1      
quadrant[DV <0 & C_mI>0] <- 2
quadrant[DV >0 & C_mI<0] <- 3
```

- Lastly, places non-significant Moran in the category 0.

```{r eval=TRUE, echo = TRUE}
quadrant[localMI[,5]>signif] <- 0

```

- In fact, we can combine all the steps into one single code chunk as shown below:

```{r eval=TRUE, echo = TRUE}
quadrant <- vector(mode="numeric",length=nrow(localMI))
DV <- hunan$GDPPC - mean(hunan$GDPPC)     
C_mI <- localMI[,1] - mean(localMI[,1])    
signif <- 0.05       
quadrant[DV >0 & C_mI>0] <- 4      
quadrant[DV <0 & C_mI<0] <- 1      
quadrant[DV <0 & C_mI>0] <- 2
quadrant[DV >0 & C_mI<0] <- 3
quadrant[localMI[,5]>signif] <- 0
```

### 6.3.4 Plotting LISA map

```{r eval=TRUE, echo = TRUE}
hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

Results above show that: 

- Dark red: Cluster is high-high (GDPPC surrounded by GDPPC) or Dark blue: low-low (county with low GDPPC surrounded by low GDPPC)
- Orange: high-low, outlier where it is a county with high GDPPC surrounded by low GDPPC
- These are significant at 95% confidence interval.
- Those un-shaded areas are not significant

<br>

For effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.

```{r eval=TRUE, echo = TRUE}
gdppc <- qtm(hunan, "GDPPC")

hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(gdppc, LISAmap, asp=1, ncol=2)
```

- Have to change the code above to:

    + Light blue on the right should be a low low
    + Middle dark blue on the right show be low high

<to be changed>

Question: What statistical observations can you draw from the LISA map above?

- To input


# 7 Hot Spot and Cold Spot Area Analysis

Besides detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.

The term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).

# 7.1 Getis and Ord’s G-Statistics

- Another spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995).
- It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.

The analysis consists of three steps:

- Deriving spatial weight matrix
- Computing Gi statistics
- Mapping Gi statistics

## 7.2 Deriving distance-based weight matrix

First, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.

Two type of distance-based proximity matrix:

- fixed diatnce weight matrix; and
- adaptive distance weight matrix.

### 7.2.1 Deriving the centroid

- We will need points to associate with each polygon before we can make our connectivity graph.
- It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. 
- Use mapping function: applies a given function to each element of a vector and returns a vector of the same length. The input vector is geometry column of us.bound. The function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. 

- To get longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.

```{r eval=TRUE, echo = TRUE}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])

```

- Do the same for latitude with one key difference.
- Access the second value per each centroid with [[2]].

```{r eval=TRUE, echo = TRUE}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])

```

- Use cbind to put longitude and latitude into the same object.
- Convert to coords so that it will be less computationally expensive

```{r eval=TRUE, echo = TRUE}
coords <- cbind(longitude, latitude)

```

### 7.2.2 Determine the cut-off distance

Firstly, to determine the upper limit for distance band by using the steps below:

- Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.
- Convert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().
- Return the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.
- Remove the list structure of the returned object by using unlist().

```{r eval=TRUE, echo = TRUE}
#coords <- coordinates(hunan)
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

Results above show that:

- The largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

### 7.2.3 Computing fixed distance weight matrix

- Compute the distance weight matrix by using *dnearneigh()*.

```{r eval=TRUE, echo = TRUE}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62

```

Next, nb2listw() is used to convert the nb object into spatial weights object. The input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.

- style can take values “W”, “B”, “C”, “U”, “minmax” and “S”.

    + B is the basic binary coding
    + W is row standardised (sums over all links to n),
    + C is globally standardised (sums over all links to n),
    + U is equal to C divided by the number of neighbours (sums over all links to unity)
    + S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).

- If zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitraty numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.


```{r eval=TRUE, echo = TRUE}
wm62_lw <- nb2listw(wm_d62, style = 'B')
summary(wm62_lw)
```

### 7.2.4 Computing adaptive distance weight matrix

One of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.

It is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.

```{r eval=TRUE, echo = TRUE}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

- nb2listw() is used to convert the nb object into spatial weights object.

```{r eval=TRUE, echo = TRUE}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```



## 7.3 Computing Gi statistics

### 7.3.1 Gi statistics using fixed distance


```{r eval=TRUE, echo = TRUE}
fips <- order(hunan$County)
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```

Results above show that:

- The output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.
- The Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.

<br>

- Join the Gi values to their corresponding hunan sf data frame by using the code chunk below.
- The 3 sub tasks are: 

    + it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix().c
    + cbind() is used to join hun@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. 
    + Field name of the gi values is renamed to gstat_fixed by using names().

```{r eval=TRUE, echo = TRUE}
hunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

### 7.3.2 Mapping Gi values with fixed distance weights

- Functions used to map the Gi values derived using fixed distance weight matrix.

```{r eval=TRUE, echo = TRUE}
gdppc <- qtm(hunan, "GDPPC")

Gimap <-tm_shape(hunan.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```

- Right map is global while right map is local
- Effect is clearer on the right map (to detect hot and cold spots)

Question: What statistical observation can you draw from the Gi map above?

- To input


### 7.3.3 Gi statistics using adaptive distance

- Compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).

```{r eval=TRUE, echo = TRUE}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

### 7.3.4 Mapping Gi values with adaptive distance weights

- Visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.
- The code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.

```{r eval=TRUE, echo = TRUE}
gdppc <- qtm(hunan, "GDPPC")

Gimap <- tm_shape(hunan.gi) +
  tm_fill(col = "gstat_adaptive", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```

- The map using adaptive distance weights is more smooth compared to the map using fixed distance weights.


Question: What statistical observation can you draw from the Gi map above?

- To input 

