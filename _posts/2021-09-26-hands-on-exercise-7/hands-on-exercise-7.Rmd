---
title: "Hands-on Exercise 7"
description: |
  In Hands-on Exercise 7, I have learnt how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package.
author:
  - name: Wong Wei Ling
    url: www.google.com
date: 09-26-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# 1 Objectives

In spatial policy, one of the main development objective of the local govenment and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”

In this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.(https://en.wikipedia.org/wiki/Hunan)

# 2 Data

- Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.
- Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.

# 3 Packages Used

- sf is use for importing and handling geospatial data in R,
- tidyverse is mainly use for wrangling attribute data in R,
- spdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and
- tmap will be used to prepare cartographic quality chropleth map.

```{r eval=TRUE, echo = TRUE}
packages = c('sf', 'spdep', 'tmap', 'tidyverse')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
```

# 4 Getting the Data Into R Environment

Bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv format.

# 4.1 Import shapefile into r environment

- Uses *st_read()* of **sf** package to import Hunan shapefile into R.
- The imported shapefile will be simple features Object of sf.

```{r eval=TRUE, echo = TRUE}
hunan <- st_read(dsn = "data/shapefile", 
                 layer = "Hunan")
```

# 4.2 Import csv file into r environment

- Import Hunan_2012.csv into R by using read_csv() of readr package.
- The output is R data frame class.

```{r eval=TRUE, echo = TRUE}
hunan2012 <- read_csv("data/attribute/Hunan_2012.csv")
```

# 4.3 Performing relational join

- To update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe.
- This is performed by using left_join() of dplyr package.

```{r eval=TRUE, echo = TRUE}
hunan <- left_join(hunan,hunan2012)
```

# 4.4 Visualising Regional Development Indicator

- Prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.

```{r eval=TRUE, echo = TRUE}
basemap <- tm_shape(hunan) +
  tm_polygons() +
  tm_text("NAME_3", size=0.5)

gdppc <- qtm(hunan, "GDPPC")
tmap_arrange(basemap, gdppc, asp=1, ncol=2)
```

# 5 Global Spatial Autocorrelation

Compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.

## 5.1 Computing Contiguity Spatial Weights

Before we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.

- In the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area.
- This function builds a neighbours list based on regions with contiguous boundaries.
- Can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.

Code chunk below is used to compute Queen contiguity weight matrix.

```{r eval=TRUE, echo = TRUE}
wm_q <- poly2nb(hunan, queen=TRUE)
summary(wm_q)
```

Results above show that:

- There are 88 area units in Hunan.
- The most connected area unit has 11 neighbours.
- There are two area units with only one neighbours.

## 5.1.1 Row-standardised weights matrix

- Next, we need to assign weights to each neighboring polygon.
- In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values.
- While this is the most intuitive way to summaries the neighbors’ values it has one **drawback** in that polygons along the edges of the study area will be based on their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.
- For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other **more robust options are available, notably style=“B”**.

<br>

- zero.policy=TRUE option allows for lists of non-neighbors.
This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.

```{r eval=TRUE, echo = TRUE}
rswm_q <- nb2listw(wm_q, style="W", zero.policy = TRUE)
rswm_q
```

## 5.2 Global Spatial Autocorrelation: Moran’s I

Perform Moran’s I statistics testing by using moran.test() of spdep.

## 5.2.1 Maron’s I test

- The code chunk below performs Moran’s I statistical testing using moran.test() of spdep.

```{r eval=TRUE, echo = TRUE}
moran.test(hunan$GDPPC, listw=rswm_q, zero.policy = TRUE, na.action=na.omit)

```

Question: What statistical conclusion can you draw from the output above?




```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```


```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```


```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```


```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```



```{r eval=TRUE, echo = TRUE}

```

