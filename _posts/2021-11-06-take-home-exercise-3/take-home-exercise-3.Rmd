---
title: "Take-home Exercise 3"
description: |
  To explain factors affecting the resale prices of public housing in Singapore.
author:
  - name: Wong Wei Ling
    url: www.google.com
date: 11-06-2021
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_float: true
    number_sections: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```



# 1 Objectives

To build hedonic pricing models to explain factors affecting the resale prices of public housing in Singapore. The hedonic price models must be built by using appropriate GWR methods. This study focuses on four-room flat and transaction period from 1st January 2019 to 30th September 2020.

# 2 Dataset

- data.gov.sg

    + [Resale Flat Price](https://data.gov.sg/dataset/resale-flat-prices)
    + [Master Plan 2014 Subzone Boundary (Web)](https://data.gov.sg/dataset/master-plan-2014-subzone-boundary-web) in shapefile format (i.e. MP14_SUBZONE_WEB_PL)
    + [School Directory and Information](https://data.gov.sg/dataset/school-directory-and-information)

- [OneMapAPISG](https://www.onemap.gov.sg/docs/#themes) 

    + Eldercare
    + Hawker Centres
    + Parks
    + Supermarkets
    + Kindergarten
    + Childcare

- [LTA Data Mall](https://datamall.lta.gov.sg/content/datamall/en/static-data.html)

    + Bus Stops
    + MRT Stations

- [ValaryLim - Github](https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper/blob/master/mall_coordinates_updated.csv)

    + Shopping Malls


# 3 Install and Load Packages

```{r echo=TRUE, eval=TRUE}
packages = c('tidyverse', 'sf', 'spdep', 'tmap', 'ggpubr',
             'corrplot', 'units', 'olsrr', 'plyr',
             'matrixStats', 'GWmodel', 'httr')

for (p in packages){
if(!require(p, character.only = T)){
  install.packages(p)
}
  library(p,character.only = T)
}
```

Explanation on the uses of each package:

- **tidyverse**: For data import and tidying. It also consist of several other packages specified below. 

    + **readr**: For importing CSV files
    + **dplyr**: For data manipulation
    + **ggplot2**: For plotting graphics
    
- **sf & spdep:** For spatial data handling
    
- **tmap:** For choropleth mapping

- **ggpubr:** For arranging tmaps to be side-by-side for easy visualisation

- **corrplot:** For multivariate data visualisation and analysis

- **matrixStats** &  **units:** For matrix manipulation

- **olsrr:** For building OLS and performing diagnostics tests

- **plyr:** For easy data manipulation

- **GWmodel:** For calibrating geographical weighted family of models

- **httr:** For API calls

# 4 Data Import and Preparation for Geospatial Dataset

In this section, we have to import and ensure that the geospatial data is in a format that we can use to perform analysis. We have to check if it is being assigned the right CRS and code. Also, since we are working in the boundary of Singapore, we have to ensure that it is in SVY21 with the EPSG code of 3414 being assigned as well. 

The datasets that we will prepare in this section are:

- Singapore's boundary: *MP14_SUBZONE_WEB_PL*
- MRT: *MRTLRTStnPtt*
- Bus stops: *BusStop*

## 4.1 Import geospatial data set

- All of the datasets are currently in ESRI shapefile format
- *st_read()* of **sf** package to import the geospatial data set.
- The imported shapefile will be a simple feature object of sf.

```{r echo=TRUE, eval=TRUE}
mpsz_sf <- st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
mrt_sf <- st_read(dsn = "data/geospatial", layer = "MRTLRTStnPtt")
bus_sf <- st_read(dsn = "data/geospatial", layer = "BusStop")
```

## 4.2 Look into datasets

- *glimpse()* of **dplyr** package to take a look at our datasets

```{r echo=TRUE, eval=TRUE}
glimpse(mpsz_sf)
glimpse(mrt_sf)
glimpse(bus_sf)
```

Results above show that: 

- There are **323 multi-polygon features** and **16 fields** in the *mpsz_sf* sf data frame.
- There are **185 point features** and **4 fields** in the *mrt_sf* sf data frame.
- There are **5,156 point features** and **4 fields** in the *bus_sf* sf data frame.
- SVY21 is the Projected Coordinates Reference System for all data sets.

## 4.3 Check for NA values

- *rowSums()* and *is.na()* of **Base R** to check for NA values

```{r echo=TRUE, eval=TRUE}
mpsz_sf[rowSums(is.na(mpsz_sf))!=0,]
mrt_sf[rowSums(is.na(mrt_sf))!=0,]
bus_sf[rowSums(is.na(bus_sf))!=0,]
```

Results above show that: 

- *mpsz_sf* and *mrt_sf* has no NA values
- *bus_sf* has 1 NA value

## 4.4 Remove NA values

- *rowSums()* and *is.na()* of **Base R** to remove NA values

```{r echo=TRUE, eval=TRUE}
bus_sf <- bus_sf[!rowSums(is.na(bus_sf))!=0,]
```

## 4.5 Check for NA values

- *rowSums()* and *is.na()* of **Base R** to check for NA values

```{r echo=TRUE, eval=TRUE}
mpsz_sf[rowSums(is.na(mpsz_sf))!=0,]
mrt_sf[rowSums(is.na(mrt_sf))!=0,]
bus_sf[rowSums(is.na(bus_sf))!=0,]
```

Results above show that:

- There are no longer any NA values

## 4.6 Check for duplicate values

- *duplicated()* of **Base R** to check for duplicated values

```{r echo=TRUE, eval=TRUE}
mrt_sf[duplicated(mrt_sf$STN_NAME),]
bus_sf[duplicated(bus_sf$BUS_STOP_N),]
```

Results above show that:

- There are 19 duplicated values in *mrt_sf*
- There are 16 duplicated values in *bus_sf*

## 4.7 Remove duplicated values

- *duplicated()* of **Base R** to remove duplicated values

```{r echo=TRUE, eval=TRUE}
mrt_sf <- mrt_sf[!duplicated(mrt_sf$STN_NAME),]
bus_sf <- bus_sf[!duplicated(bus_sf$BUS_STOP_N),]
```

## 4.8  Check for duplicated values

- *duplicated()* of **Base R** to check for duplicated values

```{r echo=TRUE, eval=TRUE}
mrt_sf[duplicated(mrt_sf$STN_NAME),]
bus_sf[duplicated(bus_sf$BUS_STOP_N),]
```

Results above show that:

- There are no longer any duplicated values in both datasets.

## 4.9 Check CRS

- Check CRS using *st_crs()* of **sf** package.
- Singapore is using SVY21. 

```{r echo=TRUE, eval=TRUE}
st_crs(mpsz_sf)
st_crs(mrt_sf)
st_crs(bus_sf)
```

From the results above:

- Referencing from [epsg.io](https://epsg.io/3414), the EPSG code of SVY21 is supposed to be 3414.
- The EPSG code shown is 9001 which is incorrect. 

## 4.10 Assign CRS and check again

- *st_set_crs()* of **sf** package to assign correct EPSG code to SpatialPointsDataFrame.
- Do not have to use *st_transform()* since it is already in SVY21.
- *st_crs()* of **sf** package to verify the CRS again. 

```{r echo=TRUE, eval=TRUE}
mpsz_sf <- st_set_crs(mpsz_sf, 3414)
mrt_sf <- st_set_crs(mrt_sf, 3414)
bus_sf <- st_set_crs(bus_sf, 3414)

st_crs(mpsz_sf)
st_crs(mrt_sf)
st_crs(bus_sf)
```

Results above show that:

- The correct EPSG code of 3414 is being assigned 

## 4.11 Check for invalid geometries

- *st_is_valid()* of **sf** package is used to check for any invalid geometries.
- *length()* of **Base R** to count the number of invalid geometries.

```{r echo=TRUE, eval=TRUE}
length(which(st_is_valid(mpsz_sf) == FALSE))
length(which(st_is_valid(mrt_sf) == FALSE))
length(which(st_is_valid(bus_sf) == FALSE))
``` 

Results above show that:

- *mpsz_sf* has 9 invalid geometries
- *mrt_sf* and *bus_sf* has 0 invalid geometries
- Hence, we have to handle these invalid geometries

## 4.12 Handle the invalid geometries and check again

- *st_make_valid()* of **sf** package to handle the invalid geometries in  *mpsz_sf*.
- *st_is_valid()* of **sf** package is used to verify that there are no longer any invalid geometries.

```{r echo=TRUE, eval=TRUE}
mpsz_sf <- st_make_valid(mpsz_sf)

length(which(st_is_valid(mpsz_sf) == FALSE))
length(which(st_is_valid(mrt_sf) == FALSE))
length(which(st_is_valid(bus_sf) == FALSE))
```

Results above show that:

- There are no longer any invalid geometries.

## 4.13 Plot geospatial data

- Reveal the distribution of HDB resale units prices in Singapore
- Create an interactive point symbol map using tmap_mode("view")

- tm_dots():
    
    + Set alpha value to 0.4,
    + colour to blue
    + size of dots to 0.03
    
- Lastly, tmap_mode(“plot”) to display plot mode

```{r echo=TRUE, eval=TRUE}
tmap_mode('view')
tm_shape(mpsz_sf) +
  tm_polygons() +
tm_shape(bus_sf) +
  tm_dots(alpha = 0.4,
          col = "blue",
          size = 0.03)
tmap_mode('plot')
```

Results above show that:

- There are about bus stops that are outside of Singapore's boundary, namely, **46239**, **46609**, **47701**, **46211**, **46219**   
- There are designated bus stops located at Johor Bahru as we are able to travel to and fro Johor Bahru with specific buses. 
- Hence, we should remove these bus stops before moving on with our analysis since they are not within Singapore boundary.

## 4.14 Remove bus stops outside of Singapore boundary

### 4.14.1 Inspect names of bus stop

- Save the bus stops identified in **Section 4.13** in a list
- Inspect names of bus stop

```{r echo=TRUE, eval=TRUE}
remove_busstop <- list(46211, 46219, 46239, 46609, 47701)
bus_sf[bus_sf$BUS_STOP_N %in% remove_busstop, ]
```

Results above show that:

- The names of these bus stops  shows that the bus stops locations indeed are in Johor Bahru.  

### 4.14.2 Remove bus stops from bus stop data

- Remove bus stops as long as they are in *remove_busstop*, identified in **Section 4.14.1**

```{r echo=TRUE, eval=TRUE}
bus_sf <- bus_sf[!bus_sf$BUS_STOP_N %in% remove_busstop, ]
```

### 4.14.3 Check if bus stops are removed

```{r echo=TRUE, eval=TRUE}
bus_sf[bus_sf$BUS_STOP_N %in% remove_busstop, ]
```

Results above show that:

- The identified bus stops have been removed.



# 5 Data Import and Preparation of Aspatial Dataset

In this section, we will prepare the aspatial data sets which will be our independent variables for calibrating the hedonic pricing models in the later section. 

**Note**: This section will **not be ran** to save computational time. **Documentation** on the ***results** are still **written** even though the **output is not shown**.

The *datasets* that we will prepare in this section are:

- Resale that consists of preparing floor level and remaining lease.
- Eldercare
- Hawker centres
- Park
- Primary school
- Shopping mall
- Supermarket 
- Kindergartens
- Childcare centres

## 5.1 Import aspatial data sets

- *read_csv()* of **readr** package to import the aspatial data sets.

```{r echo=TRUE, eval=FALSE}
resale <- read_csv("data/aspatial/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv")
eldercare <- read_csv("data/aspatial/eldercare.csv")
hawker <- read_csv("data/aspatial/hawkercentre.csv")
park <- read_csv("data/aspatial/park.csv")
prisch <- read_csv("data/aspatial/general-information-of-schools.csv")
mall <- read_csv("data/aspatial/mall.csv")
supermarket <- read_csv("data/aspatial/supermarkets.csv")
kindergarten <- read_csv("data/aspatial/kindergarten.csv")
childcare <- read_csv("data/aspatial/childcare.csv")

```


## 5.2 Look into datasets

- *glimpse()* of **dplyr** package to take a look at our datasets

```{r echo=TRUE, eval=FALSE}
glimpse(resale)
glimpse(eldercare)
glimpse(hawker)
glimpse(park)
glimpse(prisch)
glimpse(mall)
glimpse(supermarket)
glimpse(kindergarten)
glimpse(childcare)
```

Results above show that:

- There are 110,893 rows and 11 columns in *resale* data set.
- There are 133 rows and 6 columns in *eldercare* data set.
- There are 125 rows and 24 columns in *hawker* data set.
- There are 352 rows and 8 columns in *park* data set.
- There are 346 rows and 31 columns in *prisch* data set.
- There are 184 rows and 3 columns in *mall* data set.
- There are 526 rows and 9 columns in *supermarket* data set.
- There are 448 rows and 7 columns in *kindergarten* data set.
- There are 1545 rows and 7 columns in *childcare* data set.

## 5.3 Extract and filter necessary columns and data

- *filter()* of **dplyr** package to filter  relevant data from *resale* since this study only focuses on **four-room flat** and transaction period from **1st January 2019 to 30th September 2020**. 
- *filter()* is used again to filter *prisch* since we are only interested in primary schools.
- *select()* of **dplyr** package to extract the necessary columns

```{r echo=TRUE, eval=FALSE}
resale <- resale %>%
  filter(flat_type == "4 ROOM",
         month >= "2019-01" & month <= "2020-09")

eldercare <- eldercare %>%
  select(NAME, Lng, Lat)

hawker <- hawker %>%
  select(NAME, Lng, Lat)

park <- park %>%
  select(NAME, Lng, Lat)

prisch <- prisch %>%
  filter(mainlevel_code == "PRIMARY") %>%
  select(school_name, address, gifted_ind)
  
supermarket <- supermarket %>%
  select(NAME, Lng, Lat)

kindergarten <- kindergarten %>%
  select(NAME, Lng, Lat)

childcare <- childcare %>%
  select(NAME, Lng, Lat)
```

## 5.4 Look into datasets again

- *glimpse()* of **dplyr** package to take a look at our datasets

```{r echo=TRUE, eval=FALSE}
glimpse(resale)
glimpse(eldercare)
glimpse(hawker)
glimpse(park)
glimpse(prisch)
glimpse(mall)
glimpse(supermarket)
glimpse(kindergarten)
glimpse(childcare)
# glimpse(bus)
```

Results above show that:

- Notice that the number of rows and columns have changed after filtering and selecting
- There are 15901 rows and 11 columns in *resale* data set.
- There are 133 rows and 3 columns in *eldercare* data set.
- There are 125 rows and 3 columns in *hawker* data set.
- There are 352 rows and 3 columns in *park* data set.
- There are 182 rows and 3 columns in *prisch* data set.
- There are 184 rows and 3 columns in *mall* data set.
- There are 526 rows and 3 columns in *supermarket* data set.
- There are 448 rows and 3 columns in *kindergarten* data set.
- There are 1545 rows and 3 columns in *childcare* data set.

## 5.5 Check for NA values

- *is.na()* of **Base R** to check for NA values.
- *rowSums()* of **Base R** to sum the number of NA values. 

```{r echo=TRUE, eval=FALSE}
resale[rowSums(is.na(resale))!=0,]
eldercare[rowSums(is.na(eldercare))!=0,]
hawker[rowSums(is.na(hawker))!=0,]
park[rowSums(is.na(park))!=0,]
prisch[rowSums(is.na(prisch))!=0,]
mall[rowSums(is.na(mall))!=0,]
supermarket[rowSums(is.na(supermarket))!=0,]
kindergarten[rowSums(is.na(kindergarten))!=0,]
childcare[rowSums(is.na(childcare))!=0,]

```

Results above show that:

- All data sets do not contain any NA values


## 5.6 Prepare **resale** Dataset

*resale* dataset has a section on its own as there are different preparation steps to be done:

- Geo-code to extract its latitude and longitude
- Prepare *storey_range* and *remaining_lease* columns

### 5.6.1 Rename value in column

- OneMapApi can only geo code if value is replaced to *SAINT*
- *gsub()* of **Base R** to replace value in column, *street_name*

```{r echo=TRUE, eval=FALSE}
resale$street_name <- gsub("ST\\.", "SAINT", resale$street_name)
```

### 5.6.2 Combine columns for geo-coding

- *mutate()* of **dplyr** package to create a new column namely *address*, containing *block* and *street_name* columns with a space as a separator.

```{r echo=TRUE, eval=FALSE}
resale <- resale %>%
  mutate(`address` = paste(`block`, `street_name`, sep=' '))
```

### 5.6.3 Onemap API for geo-coding

#### 5.6.3.1 Function to geo code

This function does the following:

- Specifies the URL for the API
- Defines search query
- *GET()* of **httr** package to extract the request output
- *content()* of **httr** package to extract content from the request output
- *as.data.frame()* of **Base R** to convert the request to a dataframe
- *select()* of **dplyr** package to select the columns: X, Y coordinates, Longitude and Latitude
- Returns the above as a *datafame* in the *output* variable

```{r echo=TRUE, eval=FALSE}
library(httr)

geo_code <- function(address) {
  url <- "https://developers.onemap.sg/commonapi/search"
  query <- list("searchVal" = address, "returnGeom" = "Y", "getAddrDetails" = "N") #, "pageNum" = "1"
  res <- GET(url, query = query, verbose())

  output <- content(res) %>%
    as.data.frame() %>%
    select(results.X, results.Y, results.LONGITUDE, results.LATITUDE)

  return(output)
}
```

#### 5.6.3.2 For loop to apply function (row 1 to 1000)

This code chunk:

- Assigns 0 to the X, Y coordinates, Longitude and Latitude column in *resale*
- For loop to apply *geo_code* function defined in **Section 5.6.3.1** on the *resale* dataset, from row 1 to 1000
- Assigns the extracted X, Y coordinates, Longitude and Latitude into the respective columns.

```{r echo=TRUE, eval=FALSE}
resale$X <- 0
resale$Y <- 0
resale$LONGITUDE <- 0 
resale$LATITUDE <- 0 

for (i in 1:1000) {
  output <- geo_code(resale$address[i])

  resale$X[i] <- output$results.X
  resale$Y[i] <- output$results.Y
  resale$LONGITUDE[i] <- output$results.LONGITUDE
  resale$LATITUDE[i] <- output$results.LATITUDE
}
```

#### 5.6.3.3 For loop to apply function (row 1001 and beyond)

- This code chunk is similar to the one above in **Section 5.6.3.2**. 
- The only difference is, each time the for loop is ran, we have to change it to an interval of 1000. i.e. 1st run - 1001:2000, 2nd run - 2001:3000, 3rd run - 3001:4000 etc., until 15901
- We have to run multiple times (with interval of 1000) as Rstudio hangs if the entire 15901 rows are being ran at the same time. 
- The code chunk below only **shows** the **last run** (15001:15901)

```{r echo=TRUE, eval=FALSE}
for (i in 15001:15901) {
  output <- geo_code(resale$address[i])
  
  if (resale$X[i] == 0) {
    resale$X[i] <- output$results.X
    resale$Y[i] <- output$results.Y
    resale$LONGITUDE[i] <- output$results.LONGITUDE
    resale$LATITUDE[i] <- output$results.LATITUDE
  }
}
```

#### 5.6.3.4 Write into .csv file

- *write_CSV()* of **readr** package to write combined data set as a .CSV file

```{r echo=TRUE, eval=FALSE}
write_csv(resale, "data/aspatial/final_resale_prices_XY_LongLat.csv")
```

### 5.6.4 Import .csv file

- *read_CSV()* of **readr** package to import the above exported .CSV file
- *glimpse()* of **dplyr** package to take a look at our dataset

```{r echo=TRUE, eval=FALSE}
resale_new <- read_csv("data/aspatial/final_resale_prices_XY_LongLat.csv")
glimpse(resale_new)
```

Results above show that:

- There are 15901 rows and 16 columns in *resale* dataset.

### 5.6.5 Extract necessary columns

- *select()* of **dplyr** package to extract necessary columns

```{r echo=TRUE, eval=FALSE}
resale_new <- resale_new %>%
  select(month, town, flat_type, storey_range, floor_area_sqm, remaining_lease, resale_price, address, LONGITUDE, LATITUDE)
```

### 5.6.6 Manipulate *storey_range* column

- *mutate()* of **dplyr** package to create yesno column with values 1
- *pivot_wider()* of **tidyr** package to create columns from *storey_range* and input 1 or 0 (dummy variable)

```{r echo=TRUE, eval=FALSE}
resale_new <- resale_new %>%
  mutate(yesno = 1) %>%
  distinct %>%
  pivot_wider(names_from = storey_range, values_from = yesno, values_fill = 0)
```


### 5.6.7 Manipulate *remaining_lease* column

- *gsub()* of **Base R** to remove the words *years* and *months* in *remaining_lease* column
- *substr()* and *substring()* of **Base R** to place years and months in separate columns
- *as.double()* of **Base R** to convert to a *double* data type
- *is.na()* of **Base R** to locate NA values. Then, replace the NA values with 0.
- *mutate()* of **dplyr** to create a new column that contains the *remaining lease calculated in years*.

- Lastly, remove unnecessary columns:

    + *names()* of **Base R** to get names of *resale_new* data frame
    + Use %in% to drop columns specified in *drop*
    
```{r echo=TRUE, eval=FALSE}
resale_new$remaining_lease_new <- gsub("years", "", paste(resale_new$remaining_lease))
resale_new$remaining_lease_new <- gsub("month", "", paste(resale_new$remaining_lease_new))
resale_new$remaining_lease_new <- gsub("s", "", paste(resale_new$remaining_lease_new))

resale_new$remaining_lease_yr <- substr(resale_new$remaining_lease_new, start = 1, stop = 2)
resale_new$remaining_lease_mth <- substring(resale_new$remaining_lease_new, 5, 6)

resale_new$remaining_lease_yr <- as.double(resale_new$remaining_lease_yr)
resale_new$remaining_lease_mth <- as.double(resale_new$remaining_lease_mth)


resale_new$remaining_lease_mth[is.na(resale_new$remaining_lease_mth)] <- 0

resale_new <- resale_new %>%
  mutate(`remaining_lease_final` = `remaining_lease_yr` + round((`remaining_lease_mth`/12),2))

drop <- c("remaining_lease_new", "remaining_lease_yr", "remaining_lease_mth")
resale_new <- resale_new[, !names(resale_new) %in% drop]

```


## 5.7 Prepare **prisch** (primary school) Dataset

*prisch* dataset has a section on its own as there are different preparation steps to be done:

- Geo-code to extract its latitude and longitude
- Verify if all latitude and longitude have been extracted. If not, assign them
- Filter good primary school

### 5.7.1 Apply *geo_code* function

This code chunk:

- Assigns 0 to Longitude and Latitude column in *prisch*
- For loop to apply *geo_code* function defined in **Section 5.6.3.1** on the *prisch* dataframe
- *tryCatch()* of **Base R** for the code to continue running even when there is error in the geo coding.
- Assigns the extracted longitude and latitude into the respective columns, back to *prisch* dataframe

```{r echo=TRUE, eval=FALSE}
prisch$LONGITUDE <- 0 
prisch$LATITUDE <- 0 

count <- 0
failed_count <- 0

for (i in 1:183){
  tryCatch( {
    output <- geo_code(prisch$address[i])
    count <- count + 1
    prisch$LONGITUDE[i] <- output$results.LONGITUDE
    prisch$LATITUDE[i] <- output$results.LATITUDE

  }, error = function(err) {
      count <- count + 1
      failed_count <- failed_count + 1
      cat('Failed to extract',count,'out of',length(prisch$address),'addresses')
    }
  )
}
```


### 5.7.2 Write output into a CSV file

- *write_CSV()* of **readr** package to write combined data set as a .CSV file

```{r echo=TRUE, eval=FALSE}
write_csv(prisch, "data/aspatial/prisch.csv")
```


### 5.7.3 Import *prisch* Dataset

- *read_CSV()* of **readr** package to import the above exported .CSV file
- *glimpse()* of **dplyr** package to take a look at our dataset

```{r echo=TRUE, eval=FALSE}
prisch <- read_csv("data/aspatial/prisch.csv")
glimpse(prisch)
```

Results above show that:

- There are 183 rows and 5 columns in *prisch*

### 5.7.4 Verify that all primary schools have Latitude & Longitude

#### 5.7.4.1 Find primary schools with missing Latitude & Longitude

- There might be schools with missing latitude and/or longitude since in **Section 5.7.1**, a tryCatch() is ran.
- Hence, this code is to check if there are primary schools with missing latitude and/or longitude

```{r echo=TRUE, eval=FALSE}
prisch$school_name[prisch$LONGITUDE==0.0000]
```

Results above show that:

- There are indeed 4 schools, namely, HOUGANG PRIMARY SCHOOL, JING SHAN PRIMARY SCHOOL, WEST GROVE PRIMARY SCHOOL and WHITE SANDS PRIMARY SCHOOL with missing Latitude & Longitude.

#### 5.7.4.2 Assign Latitude & Longitude

- Get Latitude & Longitude from: [gps-coordinates.net](https://www.gps-coordinates.net/map/country/SG)
- HOUGANG PRIMARY SCHOOL's Long & Lat: 103.881072, 1.3783581
- JING SHAN PRIMARY SCHOOL's Long & Lat: 103.8520152, 1.3722578
- WEST GROVE PRIMARY SCHOOL's Long & Lat: 103.6989833, 1.3446809
- WHITE SANDS PRIMARY SCHOOL's Long & Lat: 103.9612546, 1.365473
- Assign the lat and long to the respective schools.

```{r echo=TRUE, eval=FALSE}
prisch$LONGITUDE[prisch$school_name == "HOUGANG PRIMARY SCHOOL"] <- 103.881072
prisch$LATITUDE[prisch$school_name == "HOUGANG PRIMARY SCHOOL"] <- 1.3783581

prisch$LONGITUDE[prisch$school_name == "JING SHAN PRIMARY SCHOOL"] <- 103.8520152
prisch$LATITUDE[prisch$school_name == "JING SHAN PRIMARY SCHOOL"] <- 1.3722578

prisch$LONGITUDE[prisch$school_name == "WEST GROVE PRIMARY SCHOOL"] <- 103.6989833
prisch$LATITUDE[prisch$school_name == "WEST GROVE PRIMARY SCHOOL"] <- 1.3446809

prisch$LONGITUDE[prisch$school_name == "HWHITE SANDS PRIMARY SCHOOL"] <- 103.9612546
prisch$LATITUDE[prisch$school_name == "WHITE SANDS PRIMARY SCHOOL"] <- 1.365473

```


### 5.7.5 Filter good primary school

- *filter()* of **dplyr** package to filter out good primary schools using the column *gifted_ind*
- The *gifted_ind* column refers to the school that are offered the [Gifted Education Programme](https://www.moe.gov.sg/programmes/gifted-education)

```{r echo=TRUE, eval=FALSE}
gd_prisch <- prisch %>%
  filter(gifted_ind == "Yes")
```

Results above show that:

- There are 8 primary schools that are offered the Gifted Education Programme


# 6 Geospatial Wrangling

**Note**: This section will **not be ran** except for **Section 6.5** and **Section 6.6** to save computational time. **Documentation** on the **results** are still **written** even though the **output is not shown**.

The variables that we will prepare in this section are:

**Locational factors**

- Proximity to CBD
- Proximity to eldercare
- Proximity to hawker centres
- Proximity to MRT
- Proximity to park
- Proximity to good primary school
- Proximity to shopping mall
- Proximity to supermarket 
- Numbers of kindergartens within 350m
- Numbers of childcare centres within 350m
- Numbers of bus stop within 350m
- Numbers of primary school within 1km

We will then combine the above variables with *resale* dataset which consists of the prepared **Structural factors** such as:

- Area of the unit
- Floor level
- Remaining lease

## 6.1 Convert Aspatial Dataframe into a sf object

### 6.1.1 Function to convert aspatial dataframe into a sf object

This function does the following:

- *st_as_sf()* of **sf** package to convert the data frame into a simple feature data frame 
- *st_transform()* of **sf** package to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).

```{r echo=TRUE, eval=FALSE}
convert_sf <- function(df, x, y) {
  st_as_sf(df,
            coords = c(x, y),
            crs=4326) %>%
  st_transform(crs=3414)
}

```

### 6.1.2 Apply function to convert aspatial dataframes into a sf object

- Apply *convert_sf* function defined in **Section 6.1.1** to the data sets

```{r echo=TRUE, eval=FALSE}
resale_sf <- convert_sf(resale_new, "LONGITUDE", "LATITUDE")
eldercare_sf <- convert_sf(eldercare, "Lng", "Lat")
hawker_sf <- convert_sf(hawker, "Lng", "Lat")
park_sf <- convert_sf(park, "Lng", "Lat")
gd_prisch_sf <- convert_sf(gd_prisch, "LONGITUDE", "LATITUDE")
mall_sf <- convert_sf(mall, "longitude", "latitude")
supermarket_sf <- convert_sf(supermarket, "Lng", "Lat")
kindergarten_sf <- convert_sf(kindergarten, "Lng", "Lat")
childcare_sf <- convert_sf(childcare, "Lng", "Lat")
prisch_sf <- convert_sf(prisch, "LONGITUDE", "LATITUDE")
```

## 6.2 Prepare Independent Variables

### 6.2.1 Central Business District (CBD) of Singapore

- [Downtown Core](https://www.latlong.net/place/downtown-core-singapore-20616.html) is one of the central districts of Singapore. 
- Its latitude and longitude are 1.287953 and 103.851784 respectively.
- *st_as_sf()* of **sf** package to convert the data frame into a simple feature data frame 
- *st_transform()* of **sf** package to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).

```{r echo=TRUE, eval=FALSE}
longitude <- 103.851784
latitude <- 1.287953

cbd_coorinates_sf <- data.frame(longitude, latitude) %>%
  st_as_sf(., coords = c("longitude", "latitude"), crs=4326) %>%
  st_transform(crs=3414)

```

### 6.2.2 Function to calculate proximity of *variables*

This function does the following:

- *st_distance()* of **sf** package to calculate distance between 2 sf objects, with a matrix being the output
- *drop_units()* of **units** package to remove the units
- *data.frame()* of **Base R** to convert matrix into a dataframe

- *rowMins()* of **matrixStats** package to get the minimum value of each row i.e. shortest distance of *variable* to each HDB resale flat.

    + Another method; *apply()* of **Base R**, with argument *MARGIN* = **1** to apply to every row and *FUN* = **min** can also be used to get the minimum value of each row but *rowMins()* is [faster](https://www.rdocumentation.org/packages/rje/versions/1.10.16/topics/rowMins)

```{r echo=TRUE, eval=FALSE}
calulate_prox <- function(df1, df2, var) {
  distance_matrix <- st_distance(df1, df2) %>%
    drop_units()
  df1[,var] <- rowMins(distance_matrix)

  return(df1)
}
```

### 6.2.3 Apply function to calculate proximity

- Apply the function defined in **Section: 6.2.2** to calculate proximity

```{r echo=TRUE, eval=FALSE}
resale_sf <- calulate_prox(resale_sf, cbd_coorinates_sf, "cbd_prox") %>%
              calulate_prox(., eldercare_sf, "eldercare_prox") %>%
              calulate_prox(., hawker_sf, "hawker_prox") %>% 
              calulate_prox(., mrt_sf, "mrt_prox") %>%
              calulate_prox(., park_sf, "park_prox") %>%
              calulate_prox(., gd_prisch_sf, "gd_prisch_prox") %>%
              calulate_prox(., mall_sf, "mall_prox") %>%
              calulate_prox(., supermarket_sf, "supermarket_prox") 
```

### 6.2.4 Function to calculate number of *variables* within a certain distance

This function does the following:

- *st_distance()* of **sf** package to calculate distance between 2 sf objects, with a matrix being the output
- *drop_units()* of **units** package to remove the units
- *data.frame()* of **Base R** to convert matrix into a dataframe
- *rowSums()* of **Base R** to get number of *variables* within a certain distance

```{r echo=TRUE, eval=FALSE}
calculate_num <- function(df1, df2, distance, var) {
  distance_matrix <- st_distance(df1, df2) %>% 
    drop_units()
  distance_matrix <- data.frame(distance_matrix)
  df1[,var] <- rowSums(distance_matrix <= distance)
  
  return(df1)
}
```


### 6.2.5 Apply function to calculate number of *variables* within a certain distance

- Apply the function defined in **Section: 6.2.4** to calculate number of *variables* within a certain distance

```{r echo=TRUE, eval=FALSE}
resale_sf <- calculate_num(resale_sf, kindergarten_sf, 350, "kindergarten_num") %>%
              calculate_num(., childcare_sf, 350, "childcare_num") %>%
              calculate_num(., bus_sf, 350, "busstop_num") %>%
              calculate_num(., prisch_sf, 1000, "prisch_num")
```


## 6.3 Re-arrange columns in *resale_sf*

- Re-arrange columns such that all independent variables are at the back of the data frame.
- This will aid us in calibrating the model in the later steps.

```{r echo=TRUE, eval=FALSE}
col_order <- c("month", "town", "flat_type", "remaining_lease", "address",
              "resale_price", "floor_area_sqm", "remaining_lease_final", 
              "01 TO 03", "04 TO 06", "07 TO 09", "10 TO 12", "13 TO 15", "16 TO 18",
              "19 TO 21", "22 TO 24", "25 TO 27", "28 TO 30", "31 TO 33", "34 TO 36",
              "37 TO 39", "40 TO 42", "43 TO 45", "46 TO 48", "49 TO 51",
              'cbd_prox', "eldercare_prox", "hawker_prox", "mrt_prox", "park_prox",
               "gd_prisch_prox", "mall_prox", "supermarket_prox",
              "kindergarten_num", "childcare_num", "busstop_num", "prisch_num", "geometry")
resale_sf <- resale_sf[, col_order]

glimpse(resale_sf)
```

## 6.4 Write to a shp file

- *st_write()* of **sf** package to write into a shp file.

```{r echo=TRUE, eval=FALSE}
st_write(resale_sf, "data/geospatial/final_resale.shp")

```

## 6.5 Import shp file

- *st_read()* of **sf** package to import the geospatial data set.
- The imported shapefile will be a simple feature object of sf.

```{r echo=TRUE, eval=TRUE}
resale_sf <- st_read(dsn="data/geospatial", layer="final_resale")

```

## 6.6 Rename columns

- *rename()* of **dplyr** package to rename columns for easy visualisation.

```{r echo=TRUE, eval=TRUE}
resale_sf <- resale_sf %>%
  dplyr::rename(resale_price = rsl_prc, floor_area_sqm = flr_r_s, remaining_lease_final = rmnng__,
         lvl_01_TO_03 = X01TO03, lvl_04_TO_06 = X04TO06, lvl_07_TO_09 = X07TO09,
         lvl_10_TO_12 = X10TO12, lvl_13_TO_15 = X13TO15, lvl_16_TO_18 = X16TO18,
         lvl_19_TO_21 = X19TO21, lvl_22_TO_24 = X22TO24, lvl_25_TO_27 = X25TO27,
         lvl_28_TO_30 = X28TO30, lvl_31_TO_33 = X31TO33, lvl_34_TO_36 = X34TO36,
         lvl_37_TO_39 = X37TO39, lvl_40_TO_42 = X40TO42, lvl_43_TO_45 = X43TO45,
         lvl_46_TO_48 = X46TO48, lvl_49_TO_51 = X49TO51,
         cbd_prox = cbd_prx, eldercare_prox = eldrcr_, hawker_prox = hwkr_pr,
         mrt_prox = mrt_prx, park_prox = prk_prx, gd_prisch_prox = gd_prs_,
         mall_prox = mll_prx, supermarket_prox = sprmrk_, kindergarten_num  = kndrgr_,
         childcare_num  = chldcr_, busstop_num  = bsstp_n, prisch_num  = prsch_n)

```



# 7 Exploratory Data Analysis

In this section, we will perform some Exploratory Data Analysis to understand our dataset.

## 7.1 EDA using statistical graphics

### 7.1.1 Function to Plot Histogram

- *geom_histogram()* of **ggplot** package to plot a histogram to see the distribution of **resale_price**

```{r echo=TRUE, eval=TRUE}
mul_hist <- function(df, vnam, x_axis) {
  ggplot(data=df, aes(x=vnam)) +
  geom_histogram(bins=20, color="black", fill="salmon") +
        scale_x_continuous(name = x_axis)
}
```

### 7.1.2 Plot distribution of **resale_price**

- Use function created in **Section 7.1.1**  to plot histogram 

```{r echo=TRUE, eval=TRUE}
mul_hist(resale_sf, resale_sf$resale_price, "Resale Price")

```

Results above show that:

- The histogram is **right-skewed**, implying that more HDB flats were transacted at **relative lower prices**.

### 7.1.3 Normalise using Log Transformation

- Statistically, the skewed distribution can be normalised by using log transformation.
- Use *mutate()* and *log* of **dplyr** package to  derive a new variable called *resale_price_log* by using a log transformation on the variable *resale_price*

```{r echo=TRUE, eval=TRUE}
resale_sf <- resale_sf %>%
  mutate(`resale_price_log` = log(resale_price))
```

### 7.1.4 Plot **resale_price_log**

- Apply function created in **Section 7.1.1**  to plot histogram with column *resale_price_log*

```{r echo=TRUE, eval=TRUE}
mul_hist(resale_sf, resale_sf$resale_price_log, "Resale Price Log")

```

Results above show that:

- The distribution is **relatively less skewed after the transformation**.



## 7.2 Multiple Plots distribution of variables

### 7.2.1 Continuous variables - Histogram

- Apply function created in **Section 7.1.1**  to plot histogram 
- *ggarrange()* of **ggpubr** package to organise these histogram into a *2 columns* by *5 rows* small multiple plots

```{r echo=TRUE, eval=TRUE, fig.width=10, fig.height=10}
ggarrange(mul_hist(resale_sf, resale_sf$floor_area_sqm, "Floor Area Sqm"),
          mul_hist(resale_sf, resale_sf$remaining_lease_final, "Remaining Lease"),
          mul_hist(resale_sf, resale_sf$cbd_prox, "Proximity to CBD"),
          mul_hist(resale_sf, resale_sf$eldercare_prox, "Proximity to Eldercare"),
          mul_hist(resale_sf, resale_sf$hawker_prox, "Proximity to Hawker Centre"),
          mul_hist(resale_sf, resale_sf$mrt_prox, "Proximity to Mrt"),
          mul_hist(resale_sf, resale_sf$park_prox, "Proximity to Park"),
          mul_hist(resale_sf, resale_sf$gd_prisch_prox, "Proximity to Good Pri. School"),
          mul_hist(resale_sf, resale_sf$mall_prox, "Proximity to Shopping Mall"),
          mul_hist(resale_sf, resale_sf$supermarket_prox, "Proximity to Supermarket"),
    ncol = 2, nrow = 5)

```

Results above show that:

- **Structural Factors**:

    + Floor Area Sqm: It is right-skewed, implying that more HDB flats have a smaller floor area of around 90 square metres
    + Remaining Lease: It is left-skewed, implying that more HDB flats have a higher number of remaining lease period of more than 90 years.
    
- **Locational Factors**:

    + Proximity to CBD: It is left-skewed, implying that more HDB flats are further away from the CBD area of Singapore. 
    + Proximity to eldercare: It is right-skewed, implying that more HDB flats are nearer to an eldercare of less than 500m away.
    + Proximity to hawker centres: it is right-skewed, implying that more HDB flats are nearer to a hawker centre of 500m away.
    + Proximity to MRT: It is right-skewed,implying that more HDB flats are nearer to a MRT station of less than 500m away.
    + Proximity to park: It is right-skewed, implying that more HDB flats are nearer to a park of less than 800m away.
    + Proximity to good primary school: It is relatively right-skewed, implying that more HDB flats are nearer to a good primiary school of around 2000m to 4000m away.
    + Proximity to shopping mall: It is right-skewed, implying that more HDB flats are nearer to a shopping mall of less than 600m away.
    + Proximity to supermarket It is right-skewed, implying that more HDB flats are nearer to  a supermarket of less than 300m away.
  

### 7.2.2 Discrete variables - Bar Chart

#### 7.2.2.1 Function to plot bar charts

- Create function to plot bar chart, *mul_bar*
- *geom_bar()* of **ggplot** package to plot a histogram to see the distribution of the discrete variables.

```{r echo=TRUE, eval=TRUE, fig.width=10, fig.height=6}
mul_bar <- function(df, vnam, x_axis){
  ggplot(data=df, aes(x=factor(vnam))) +
    geom_bar(color="black", fill="darkseagreen3")   +
         scale_x_discrete(name = x_axis)
}

```


#### 7.2.2.2 Apply function to plot bar charts

- Use function created in **Section 7.2.2.1** to plot bar charts
- *ggarrange()* of **ggpubr** package to organise these histogram into a *2 columns* by *2 rows* small multiple plot

```{r echo=TRUE, eval=TRUE, fig.width=10, fig.height=6}
ggarrange(mul_bar(resale_sf, resale_sf$kindergarten_num, "No. of Kindergartens (within 350m)"),
          mul_bar(resale_sf, resale_sf$childcare_num, "No. of Childcare Centres (within 350m)"),
          mul_bar(resale_sf, resale_sf$busstop_num, "No. of Bus Stops (within 350m)"),
          mul_bar(resale_sf, resale_sf$prisch_num, "No. of Pri. School (within 1km)"),
      ncol = 2, nrow = 2)
```

Results above show that:

- **Locational Factors**:

    + Numbers of kindergartens within 350m: It is right-skewed, implying that more HDB flats have less kindergartens within 350m.
    + Numbers of childcare centres within 350m: It is right-skewed, implying that more HDB flats have less childcare centres within 350m.
    + Numbers of bus stop within 350m: It is slightly right-skewed, implying that slightly more HDB flats have less bus stops within 350m.
    + Numbers of primary school within 1km: It is slightly right-skewed, implying that slightly more HDB flats have less primary schools within 1km. 
    
    
### 7.2.3 Binary variables - Box Plots

#### 7.2.3.1 Function to plot bar charts

- Create function to plot bar chart, *mul_bar_level*
- *geom_bar()* of **ggplot** package to plot a histogram to see the distribution of the binary variables.

```{r echo=TRUE, eval=TRUE, fig.width=12, fig.height=10}
mul_bar_level <- function(df, vnam, x_axis){
  ggplot(data=df, aes(x=factor(vnam))) +
    geom_bar(color="black", fill="steelblue3") +  
         scale_x_discrete(name = x_axis) + coord_flip()
}

```

#### 7.2.3.2 Appply function to plot bar charts

- Use function created in **Section 7.2.3.1** to plot bar charts
- *ggarrange()* of **ggpubr** package to organise these histogram into a *2 columns* by *9 rows* small multiple plot

```{r echo=TRUE, eval=TRUE, fig.width=12, fig.height=10}
ggarrange(mul_bar_level(resale_sf, resale_sf$lvl_01_TO_03, "Level 1 to 3"),
          mul_bar_level(resale_sf, resale_sf$lvl_04_TO_06, "Level 4 to 6"),
          mul_bar_level(resale_sf, resale_sf$lvl_07_TO_09, "Level 7 to 9"),
          mul_bar_level(resale_sf, resale_sf$lvl_10_TO_12, "Level 10 to 12"),
          mul_bar_level(resale_sf, resale_sf$lvl_13_TO_15, "Level 13 to 15"),
          mul_bar_level(resale_sf, resale_sf$lvl_16_TO_18, "Level 16 to 18"),
          mul_bar_level(resale_sf, resale_sf$lvl_19_TO_21, "Level 19 to 21"),
          mul_bar_level(resale_sf, resale_sf$lvl_22_TO_24, "Level 22 to 24"),
          mul_bar_level(resale_sf, resale_sf$lvl_25_TO_27, "Level 25 to 27"),
          mul_bar_level(resale_sf, resale_sf$lvl_28_TO_30, "Level 28 to 30"),
          mul_bar_level(resale_sf, resale_sf$lvl_31_TO_33, "Level 31 to 33"),
          mul_bar_level(resale_sf, resale_sf$lvl_34_TO_36, "Level 34 to 36"),
          mul_bar_level(resale_sf, resale_sf$lvl_37_TO_39, "Level 37 to 39"),
          mul_bar_level(resale_sf, resale_sf$lvl_40_TO_42, "Level 40 to 42"),
          mul_bar_level(resale_sf, resale_sf$lvl_43_TO_45, "Level 43 to 45"),
          mul_bar_level(resale_sf, resale_sf$lvl_46_TO_48, "Level 46 to 48"),
          mul_bar_level(resale_sf, resale_sf$lvl_49_TO_51, "Level 49 to 51"),
      ncol = 2, nrow = 9)

```

Results above show that:

- **Structural Factor**:

    + Floor levels: There are more HDB resale flats that are on lower levels than higher levels. 
    

## 7.3 Drawing Statistical Point Map

- Reveal the geospatial distribution of HDB resale prices (**dependent** variable) in Singapore 

- Create an interactive point symbol map by using *tmap_mode(“view”)*

    + *tm_dots()* with col = resale_price
    + set.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.

- Use *tmap_mode(“plot”)* to display plot mode of tmap
- All of the above are using **tmap** package

```{r echo=TRUE, eval=TRUE}
tmap_options(check.and.fix = TRUE)

tmap_mode("view")

tm_shape(mpsz_sf)+
  tm_polygons() +
tm_shape(resale_sf) +
  tm_dots(col = "resale_price",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))

tmap_mode("plot")
```


Results above show that:

- The **Central** region of Singapore tends to have a **higher** HDB resale prices for 4 room flats since it appears to be darker in that area.


# 8 Hedonic Pricing Modelling in R

In this section, we will build hedonic pricing models for HDB resale units using *lm()* of **Base R**.

## 8.1 Multiple Linear Regression Method

### 8.1.1 Visualise relationships of independent variables

Before we start calibrating the Hedonic Pricing Model, we have to ensure that the independent variables used are not highly correlated to each other. This is called **multicollinearity** in statistics.

#### 8.1.1.1 Drop geometry column

- To plot a correlation plot, the geometry column must be dropped.
- *st_drop_geometry()* of **sf** package to drop the geometry column in *resale_sf*

```{r echo=TRUE, eval=TRUE}
resale_sf_nogeom <- resale_sf %>%
  st_drop_geometry()
```

