---
title: "Take-Home Exercise 2"
description: |
  To investigate if the distribution of Airbnb listings are affected by location factors and to analyse the impact of COVID-19 on Airbnb business in Singapore.
author:
  - name: Wong Wei Ling
    url: www.google.com
date: 09-30-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
set.seed(1234)
```


# 1 Objectives

- To investigate if the distribution of Airbnb listings are affected by location factors such as near to existing hotels, MRT services and tourist attractions. 
- To analyse the impact of COVID-19 on Airbnb business in Singapore by comparing Airbnb listings data on June 2019 and June 2021

# 2 Dataset

- Airbnb listings for June 2019 and June 2021 from Inside Airbnb.
- Hotels, tourist attractions, MRT services and other appropriate geospatial data sets were supposed to be extracted from SLA OneMap Service by using onemapsgapi. However, due to some issues of creating a onemap account, Prof. Kam has kindly provided us with the data in CSV format. 
- Coastaloutline is used for binding the Singapore boundary which is also provided by Prof. Kam. 
- Sub zones from data.gov.sg 

# 3 Install and Load Packages

```{r echo=TRUE, eval=TRUE}
packages = c('tidyverse', 'sf', 'tmap', 'maptools', 'spatstat', 'raster', 'gridExtra') #  'sp', 'spNetwork', 'readr', 'dplyr',  , 'ggplot2', 'ggpubr', 'rgdal', 'ggthemes', 'plotly'

for (p in packages){
if(!require(p, character.only = T)){
  install.packages(p)
}
  library(p,character.only = T)
}
```

Explanation on the uses of each package:

- **tidyverse**: For data import and tidying. It also consist of several other packages specified below. 

    + **readr**: For importing CSV files
    + **dplyr**: For data manipulation
    + **ggplot2**: For plotting graphics
    
- **sf:** For importing and processing of geospatial data such as encoding spatial vector data.
    
- **tmap:** For plotting interactive maps

- **maptools:** For maanipulating geospatial data

- **spatstat:** For statistical analysis of spatial data.

- **ggpubr:** For arranging tmaps to be side-by-side for easy visualisation
    
- **raster:** For processing geospatial data to plot KDE maps on OpenStreetMap
    
- **gridExtra:** For arranging KDE maps when plotted into grid objects

# 4 Data Import and Preparation for Geospatial Dataset

In this section, we have to import and ensure that the geospatial data is a format that we can use to perform analysis. We have to check if it is being assigned the right CRS and code. Also, since we are working in the boundary of Singapore, we have to ensure that it is in SVY21 as well. 

## 4.1 Import geospatial data set

- *st_read()* of **sf** package to import the geospatial data sets.
- The imported shapefile will be a simple feature Object of sf.

```{r echo=TRUE, eval=TRUE}
mrt_sf <- st_read(dsn = "data/geospatial", layer = "MRTLRTStnPtt")
mpsz_sf <- st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
sg_sf <- st_read(dsn = "data/geospatial", layer="CostalOutline")
```

From the results above: 

- The geometry type is point, multipolygon and polygon for the mrt, mpsz and sg data set.
- The assigned CRS for all is SVY21.

## 4.2 Check CRS

- Check CRS using *st_crs()* of **sf** package.
- Singapore is using SVY21. 

```{r echo=TRUE, eval=TRUE}
st_crs(mrt_sf)
st_crs(mpsz_sf)
st_crs(sg_sf)

```

From the results above:

- Referencing from *(https://epsg.io/3414)*, the EPSG code of SVY21 is supposed to be 3414.
- The EPSG code shown is 9001 which is incorrect. 

## 4.3 Assign CRS and check again

- *st_set_crs()* of **sf** package to assign correct EPSG code to SpatialPointsDataFrame.
- Do not have to use *st_transform()* since it is already in SVY21. 
- *st_crs* of **sf** package to check the CRS again. 

```{r echo=TRUE, eval=TRUE}
mrt_sf <- st_set_crs(mrt_sf, 3414)
mpsz_sf <- st_set_crs(mpsz_sf, 3414)
sg_sf <- st_set_crs(sg_sf, 3414)

st_crs(mrt_sf)
st_crs(mpsz_sf)
st_crs(sg_sf)

```

## 4.4 Check if geometries are valid

- *st_is_valid()* is used to check for any invalid geometries.

```{r echo=TRUE, eval=TRUE}
length(which(st_is_valid(mrt_sf) == FALSE))
length(which(st_is_valid(mpsz_sf) == FALSE))
length(which(st_is_valid(sg_sf) == FALSE))

```

From the results above: 

- There are 0, 9 and 1 invalid geometries for mrt, mpsz and sg respectively

## 4.5 Handle the invalid geometries and check again

- *st_make_valid()* to make the geometries valid for the mpsz and sg data set only since MRT has no invalid geometries

```{r echo=TRUE, eval=TRUE}
mpsz_sf <- st_make_valid(mpsz_sf)
sg_sf <- st_make_valid(sg_sf)

length(which(st_is_valid(mpsz_sf) == FALSE))
length(which(st_is_valid(sg_sf) == FALSE))
```

Result above show that:

- There are no longer any invalid geometries

## 4.6 Visualise the MRT services on the Singapore map

- It is a good practice to visualise the geospatial data before continuing with the other steps.
- *tmap_mode()* of **tmap** package is used to visualise the geospatial data with high cartographic quality and interactive manner.

```{r echo=TRUE, eval=TRUE}

tm_shape(sg_sf) +
  tm_polygons() +
tm_shape(mpsz_sf) +
  tm_polygons() +
tm_shape(mrt_sf) +
  tm_dots(col="blue")

```


# 5 Data Import and Preparation for Aspatial Dataset

For aspatial data, we have to check for NA values because if NA values are not properly handled, it might hinder with the analysis in the later steps. Additionally, we have to convert them to sf objects and assign them the right CRS, making these data sets suitable to be plotted on a map. 

## 5.1 Import aspatial data sets

- *read_csv()* of **readr** package to import the aspatial data sets.

```{r echo=TRUE, eval=TRUE}
listings_2019 <- read_csv("data/aspatial/listings_June_2019.csv")
hotels <- read_csv("data/aspatial/hotels.csv")
tourism <- read_csv("data/aspatial/tourism.csv")
listings_2021 <- read_csv("data/aspatial/listings_June_2021.csv")

```

## 5.2 Look into the data sets

```{r echo=TRUE, eval=TRUE}
glimpse(listings_2019)
glimpse(hotels)
glimpse(tourism)
glimpse(listings_2021)

```


## 5.3 Data Cleaning

- Remove NA values only from latitude and longitude columns as those are needed for analysis in the later steps.
- NA values in other columns do not have to be dropped as the *data* will be dropped later when converting Spatial* data frame into Spatial* objects.

```{r echo=TRUE, eval=TRUE}
listings_2019 <- listings_2019 %>%
  drop_na(latitude) %>%
  drop_na(longitude)

hotels <- hotels %>%
  drop_na(Lat) %>%
  drop_na(Lng)

tourism <- tourism %>%
  drop_na(LATITUDE) %>%
  drop_na(LONGTITUDE)

listings_2021 <- listings_2021  %>%
  drop_na(latitude) %>%
  drop_na(longitude)

```



## 5.4 Convert Aspatial data frame into sf object and assign CRS

- The values in the latitude & longitude columns are in decimal degrees, hence, this means that it is using WGS84. 
- We then need to assign the epsg code of 4326 before transforming to SVY21.

```{r echo=TRUE, eval=TRUE}
listings_2019_sf <- st_as_sf(listings_2019,
                    coords = c("longitude", "latitude"),
                    crs = 4326)  %>%
  st_transform(crs = 3414)


hotels_sf <- st_as_sf(hotels,
                    coords = c("Lng", "Lat"),
                    crs = 4326)  %>%
  st_transform(crs = 3414)


tourism_sf <- st_as_sf(tourism,
                    coords = c("LONGTITUDE", "LATITUDE"),
                    crs = 4326)  %>%
  st_transform(crs = 3414)

listings_2021_sf <- st_as_sf(listings_2021,
                    coords = c("longitude", "latitude"),
                    crs = 4326)  %>%
  st_transform(crs = 3414)
```


## 5.5 Check CRS

- Check CRS to ensure that it is EPSG:3414 - SVY21

```{r echo=TRUE, eval=TRUE}
st_crs(listings_2019_sf)
st_crs(hotels_sf)
st_crs(tourism_sf)
st_crs(listings_2021_sf)

```

Results above show that:

- All are in the right code of 3414. 

## 5.6 Plot to review (including geospatial data, excluding listings_2021)

- Plot all the point events of Airbnb listings 2019, hotels, tourist attractions and MRT services to ensure that they are being assigned the right CRS. 

```{r echo=TRUE, eval=TRUE}
tm_shape(sg_sf) +
  tm_polygons() +
tm_shape(mpsz_sf) +
  tm_polygons() +
tm_shape(listings_2019_sf) +
  tm_dots(alpha = 0.4,
          col = "blue",
          size = 0.05) +
tm_shape(hotels_sf) +
  tm_dots(alpha = 0.4,
          col = "red",
          size = 0.05) +
tm_shape(tourism_sf) +
  tm_dots(alpha = 0.4,
          col = "green",
          size = 0.05) +
tm_shape(mrt_sf) +
  tm_dots(alpha = 0.4,
          col = "orange",
          size = 0.05)


```


## 5.7 Plot to review (including geospatial data, excluding listings_2019)

- Plot all the point events of Airbnb listings 2021, hotels, tourist attractions and MRT services to ensure that it is being assigned the right CRS. 

```{r echo=TRUE, eval=TRUE}
tm_shape(sg_sf) +
  tm_polygons() +
tm_shape(mpsz_sf) +
  tm_polygons() +
tm_shape(listings_2021_sf) +
  tm_dots(alpha = 0.4,
          col = "blue",
          size = 0.05) +
tm_shape(hotels_sf) +
  tm_dots(alpha = 0.4,
          col = "red",
          size = 0.05) +
tm_shape(tourism_sf) +
  tm_dots(alpha = 0.4,
          col = "green",
          size = 0.05) +
tm_shape(mrt_sf) +
  tm_dots(alpha = 0.4,
          col = "orange",
          size = 0.05)
```


# 6 Geospatial Data Wrangling

This section focuses on converting simple feature data frames to ppp objects that are suitable for the analysis in the later steps. 

## 6.1 Convert sf to Spatial* classes

- *as_Spatial()* of **sf** package is being used to convert the geospatial data from simple feature data frame to spâ€™s Spatial* class.

```{r echo=TRUE, eval=TRUE}
mpsz <- as_Spatial(mpsz_sf)
sg <- as_Spatial(sg_sf)
listings_2019 <- as_Spatial(listings_2019_sf)
hotels <- as_Spatial(hotels_sf)
tourism <- as_Spatial(tourism_sf)
mrt <- as_Spatial(mrt_sf)
listings_2021 <- as_Spatial(listings_2021_sf)

```


## 6.2 Convert Spatial* dataframe into Spatial* objects

- As *spatstat* requires the analytical data in ppp object and there is no direct way to convert a Spatial* class to ppp object, we have to convert the Spatial classes* into Spatial object first.
- *as()* with the argument *SpatialPoints* of **maptools** package is being used for point data sets, while *SpatialPolygons* is being used for polygonal data sets.
- Data would be dropped in this step.

```{r echo=TRUE, eval=TRUE}
mpsz_sp <- as(mpsz, "SpatialPolygons")
sg_sp <- as(sg, "SpatialPolygons")
listings_2019_sp <- as(listings_2019, "SpatialPoints")
hotels_sp <- as(hotels, "SpatialPoints")
tourisms_sp <- as(tourism, "SpatialPoints")
mrt_sp <- as(mrt, "SpatialPoints")
listings_2021_sp <- as(listings_2021, "SpatialPoints")

```


## 6.3 Convert from Spatial* objects into ppp object

- *as()* with the argument of *ppp* of **maptools** package is being used.
- Project information would be dropped in this step.

```{r echo=TRUE, eval=TRUE}
listings_2019_ppp <- as(listings_2019_sp, "ppp")
hotels_ppp <- as(hotels_sp, "ppp")
tourisms_ppp <- as(tourisms_sp, "ppp")
mrt_ppp <- as(mrt_sp, "ppp")
listings_2021_ppp <- as(listings_2021_sp, "ppp")

```

## 6.4 Summary statistics of the newly created ppp objects

```{r echo=TRUE, eval=TRUE}
summary(listings_2019_ppp)
summary(hotels_ppp)
summary(tourisms_ppp)
summary(mrt_ppp)
summary(listings_2021_ppp)

```

- From the results above,

    + Messages about duplicates are printed for listings_2019, hotels & tourism.
    + The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.


## 6.5 Find number of duplicated points

- sum() and multiplicity() to know the number of locations with more than 1 point event.

```{r echo=TRUE, eval=TRUE}
sum(multiplicity(listings_2019_ppp) > 1)
sum(multiplicity(hotels_ppp) > 1)
sum(multiplicity(tourisms_ppp) > 1)
sum(multiplicity(mrt_ppp) > 1)
sum(multiplicity(listings_2021_ppp) > 1)

```

From the results above:

- All data sets have duplicated points except for the MRT data set.

## 6.6 Handle duplicated points using jitter

- *rjitter()* of **spatstat** package is being used
- To avoid points overlapping, rjitter() will add a small perturbation to the duplicated points so that they do not occupy the exact same space 
- *any()* and *duplicated()* are used to ensure that there are no duplicated points after using *rjitter()*
- From the previous step, even though *mrt_ppp* object is being shown that there are 0 duplicated points, it is a good practice to verify by printing it again.


```{r echo=TRUE, eval=TRUE}
listings_2019_ppp_jit <- rjitter(listings_2019_ppp,
                             retry = TRUE,
                             nsim = 1,
                             drop = TRUE)
any(duplicated(listings_2019_ppp_jit))


hotels_ppp_jit <- rjitter(hotels_ppp,
                             retry = TRUE,
                             nsim = 1,
                             drop = TRUE)
any(duplicated(hotels_ppp_jit))


tourisms_ppp_jit <- rjitter(tourisms_ppp,
                             retry = TRUE,
                             nsim = 1,
                             drop = TRUE)
any(duplicated(tourisms_ppp_jit))


mrt_ppp_jit <- rjitter(mrt_ppp,
                             retry = TRUE,
                             nsim = 1,
                             drop = TRUE)
any(duplicated(mrt_ppp_jit))

listings_2021_ppp_jit <- rjitter(listings_2021_ppp,
                             retry = TRUE,
                             nsim = 1,
                             drop = TRUE)
any(duplicated(listings_2021_ppp_jit))

```

- Results above show that all are FALSE, thereby confirming that there are no duplicated points present after performing *rjitter()*.

## 6.7 Create an owin object

- It is a good practice to confine the spatial point patterns analysis with a geographical area such as the Singapore boundary.
- In **spatstat** package, this polygonal region is known as **owin**, an object specially designed to represent this boundary.

- Convert *sg* SpatialPolygon object to owin object of **spatstat** package 

```{r echo=TRUE, eval=TRUE}
sg_owin <- as(sg_sp, "owin")
```


## 6.8 Combine with owin object

- Combine point, polygonal event object and owin object into one ppp object for Airbnb listings in 2019, 2021, tourisms, hotels and MRT services.

```{r echo=TRUE, eval=TRUE}
listings_2019_ppp = listings_2019_ppp_jit[sg_owin]
tourisms_ppp = tourisms_ppp_jit[sg_owin]
hotels_ppp = hotels_ppp_jit[sg_owin]
mrt_ppp = mrt_ppp_jit[sg_owin]
listings_2021_ppp = listings_2021_ppp_jit[sg_owin]

plot(listings_2019_ppp)
```

## 6.9 Visualise the ppp objects

- *plot()* is being used to visualise the ppp objects which are confined within Singapore boundary

```{r echo=TRUE, eval=TRUE}
par(mfrow=c(2,3))

plot(listings_2019_ppp)
plot(tourisms_ppp)
plot(hotels_ppp)
plot(mrt_ppp)
plot(listings_2021_ppp)

```

## 6.10  Re-scale KDE Values

- For the analysis in the later steps, kernel density estimation (KDE) will be computed. 
- However, since the default unit of measurement of SVY21 is in metre, we have to convert the KDE values to kilometre so that the values would not be too small to look for useful insights.
- *rescale()* is used to convert the KDE values from metre to kilometre.

```{r echo=TRUE, eval=TRUE}
listings_2019_ppp.km <- rescale(listings_2019_ppp, 1000, "km")
hotels_ppp.km <- rescale(hotels_ppp, 1000, "km")
tourisms_ppp.km <- rescale(tourisms_ppp, 1000, "km")
mrt_ppp.km <- rescale(mrt_ppp, 1000, "km")
listings_2021_ppp.km <- rescale(listings_2021_ppp, 1000, "km")

```



